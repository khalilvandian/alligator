{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Comparison between Semtab Business Data and Github Dataset\n",
    "This Notbook investigates if contextual or any other features are inherently different between the 2 datasets. Existence of a significant difference would suggest reconsideration in the fine tuning data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Semtab Business Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "semtab_business_features_path = \"B:/Projects/Alligator-2/alligator/Training_Data/results/companies-correct-qids_with_cols.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "semtab_business_data_df = pd.read_csv(semtab_business_features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "semtab_business_features_df = semtab_business_data_df.groupby(\"group\").first().reset_index()\n",
    "semtab_business_features_df.drop(columns=[\"group\", \"tableName\", \"key\", \"target\"], inplace=True)\n",
    "semtab_business_features_df.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Github Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_dataset_features_path = \"B:/Projects/Alligator-2/alligator/Github_Data/github_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_dataset_data_df = pd.read_csv(github_dataset_features_path)\n",
    "github_dataset_features_df = github_dataset_data_df.drop(columns=[\"delta\", \"omega\", \"key\"])\n",
    "github_dataset_features_df.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(data_path):\n",
    "    \"\"\"\n",
    "    Reads JSON data from the specified path, extracts features for each entity,\n",
    "    and returns a DataFrame with features as columns and a custom key as the index.\n",
    "    The key is formatted as '{table_name}-{idRow}-{idColumn}' and accommodates multiple tables.\n",
    "\n",
    "    Parameters:\n",
    "        data_path (str): Path to the JSON file containing entity data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with features as columns and custom key as the index.\n",
    "    \"\"\"\n",
    "    # Read the JSON file\n",
    "    with open(data_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Initialize a list to store each row's features\n",
    "    rows = []\n",
    "\n",
    "    # Iterate over the tables (assuming 'semanticAnnotations' contains multiple tables)\n",
    "    annotations = data.get('semanticAnnotations', {}).get('cea', [])\n",
    "    if isinstance(annotations, list):  # Support single list structure as well\n",
    "        annotations = [annotations]\n",
    "\n",
    "    for table_annotations in annotations:\n",
    "        table_name = data.get(\"tableName\", \"unknown_table\")\n",
    "\n",
    "        for annotation in table_annotations:\n",
    "            # Ensure there is an entity present\n",
    "            if annotation['entity']:\n",
    "                first_entity = annotation['entity'][0]\n",
    "                id_row = annotation.get('idRow')\n",
    "                id_column = annotation.get('idColumn')\n",
    "\n",
    "                # Generate the key in the format \"{table_name}-{idRow}-{idColumn}\"\n",
    "                key = f\"{table_name}-{id_row}-{id_column}\"\n",
    "\n",
    "                # Extract features as a dictionary\n",
    "                features = {feature['id']: feature['value'] for feature in first_entity.get('features', [])}\n",
    "                features['key'] = key  # Include the custom key in the DataFrame\n",
    "\n",
    "                # Append the features dictionary to rows\n",
    "                rows.append(features)\n",
    "\n",
    "    # Create DataFrame and set 'key' as index\n",
    "    df = pd.DataFrame(rows).set_index('key')\n",
    "\n",
    "    return df\n",
    "\n",
    "def extract_distribution_statistics(features_df):\n",
    "    \"\"\"\n",
    "    Extracts statistical parameters for each feature in the DataFrame for distribution analysis.\n",
    "\n",
    "    Parameters:\n",
    "        features_df (pd.DataFrame): A DataFrame containing feature columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with ordered statistical parameters (mean, std_dev, min, 25%, median, 75%, max) for each feature.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store statistics\n",
    "    statistics = {}\n",
    "\n",
    "    # Loop through each feature column to calculate statistics\n",
    "    for column in features_df.columns:\n",
    "        # Skip non-numeric columns\n",
    "        if not pd.api.types.is_numeric_dtype(features_df[column]):\n",
    "            continue\n",
    "\n",
    "        # Calculate statistical parameters\n",
    "        stats = {\n",
    "            'mean': features_df[column].mean(),\n",
    "            'std_dev': features_df[column].std(),\n",
    "            'min': features_df[column].min(),\n",
    "            '25%': features_df[column].quantile(0.25),\n",
    "            'median': features_df[column].median(),\n",
    "            '75%': features_df[column].quantile(0.75),\n",
    "            'max': features_df[column].max(),\n",
    "        }\n",
    "\n",
    "        # Add stats to the dictionary\n",
    "        statistics[column] = stats\n",
    "\n",
    "    # Convert the statistics dictionary to a DataFrame\n",
    "    stats_df = pd.DataFrame(statistics).T  # Transpose to make features as rows\n",
    "\n",
    "    # Reorder columns\n",
    "    stats_df = stats_df[['mean', 'std_dev', 'min', '25%', 'median', '75%', 'max']]\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "def extract_correct_features(file_path):\n",
    "    \"\"\"\n",
    "    Extracts features of the correct candidate entity for each row based on `rows.ids` and `semanticAnnotations.cea`.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with extracted features for the correct entity in each row.\n",
    "    \"\"\"\n",
    "    # Load JSON data\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    extracted_data = []  # To store extracted features\n",
    "\n",
    "    # Iterate over each row to find the correct ID\n",
    "    for row in data['rows']:\n",
    "        row_id = row['idRow']\n",
    "\n",
    "        # Find the first valid ID in 'ids', ignoring empty or \"NIL\" entries\n",
    "        correct_id = next((entity_id for entity_id in row['ids'] if entity_id != \"NIL\"), None)\n",
    "\n",
    "        # Skip to the next row if there is no valid correct ID\n",
    "        if correct_id is None:\n",
    "            continue\n",
    "\n",
    "        # Search in `cea` for matching idRow with idColumn = 2\n",
    "        correct_entity = None\n",
    "        for annotation in data['semanticAnnotations']['cea']:\n",
    "            if annotation['idRow'] == row_id and annotation['idColumn'] == 2:\n",
    "                # Look for the entity with the correct ID\n",
    "                for entity in annotation['entity']:\n",
    "                    if entity['id'] == correct_id:\n",
    "                        correct_entity = entity\n",
    "                        break\n",
    "            if correct_entity:\n",
    "                break\n",
    "\n",
    "        # If the correct entity is found, extract features\n",
    "        if correct_entity:\n",
    "            features = {feature['id']: feature['value'] for feature in correct_entity.get('features', [])}\n",
    "            features['idRow'] = row_id\n",
    "            features['correct_id'] = correct_id\n",
    "            extracted_data.append(features)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "    return extracted_df\n",
    "\n",
    "def calculate_feature_correlations(features_df, method='pearson', plot=True):\n",
    "    \"\"\"\n",
    "    Calculates the correlation matrix for the features in the DataFrame and optionally\n",
    "    displays a high-resolution heatmap with a consistent color scale from -1 to +1.\n",
    "\n",
    "    Parameters:\n",
    "        features_df (pd.DataFrame): A DataFrame containing feature columns.\n",
    "        method (str): Correlation method ('pearson', 'spearman', 'kendall').\n",
    "        plot (bool): Whether to display a heatmap of the correlation matrix.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame representing the correlation matrix of the features.\n",
    "    \"\"\"\n",
    "    # Select only numeric columns for correlation calculation\n",
    "    numeric_features = features_df.select_dtypes(include=['number'])\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = numeric_features.corr(method=method)\n",
    "\n",
    "    # Plot the heatmap if plot is True\n",
    "    if plot:\n",
    "        plt.figure(figsize=(24, 20), dpi=150)  # Large figure size with high DPI\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', square=True,\n",
    "                    cbar_kws={'shrink': 0.8}, fmt=\".2f\", linewidths=0.5,\n",
    "                    vmin=-1, vmax=1)  # Set color scale to -1 to +1 for accuracy\n",
    "        plt.title(f'{method.capitalize()} Correlation Matrix', fontsize=18)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.tight_layout()  # Adjust layout for better spacing\n",
    "        plt.show()\n",
    "\n",
    "    return correlation_matrix\n",
    "\n",
    "def plot_feature_distributions(features_df):\n",
    "    \"\"\"\n",
    "    Creates a large figure with histogram charts for each feature in a grid layout,\n",
    "    and violin plots: one for features with values <= 1, and individual plots for features with values > 1.\n",
    "\n",
    "    Parameters:\n",
    "        features_df (pd.DataFrame): A DataFrame containing feature columns.\n",
    "    \"\"\"\n",
    "    # Select only numeric columns for plotting\n",
    "    numeric_features = features_df.select_dtypes(include=['number'])\n",
    "\n",
    "    # Calculate grid size based on the number of features\n",
    "    num_features = numeric_features.shape[1]\n",
    "    grid_size = math.ceil(math.sqrt(num_features))  # Square layout\n",
    "\n",
    "    # Set up the figure size and layout for histograms\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(20, 20), dpi=150)\n",
    "    axes = axes.flatten()  # Flatten to iterate easily\n",
    "\n",
    "    # Plot histograms for each feature\n",
    "    for i, column in enumerate(numeric_features.columns):\n",
    "        sns.histplot(numeric_features[column], kde=True, ax=axes[i])\n",
    "        axes[i].set_title(column)\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    # Turn off any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Adjust layout for the histograms\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Separate features based on value ranges\n",
    "    features_leq_one = numeric_features.loc[:, numeric_features.max() <= 1]\n",
    "    features_gt_one = numeric_features.loc[:, numeric_features.max() > 1]\n",
    "\n",
    "    # Plot the violin plot for features with values <= 1\n",
    "    if not features_leq_one.empty:\n",
    "        plt.figure(figsize=(20, 10), dpi=150)\n",
    "        sns.violinplot(data=features_leq_one, inner='quartile', palette='coolwarm')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.title('Distribution of Features with Values <= 1')\n",
    "        plt.show()\n",
    "\n",
    "    # Plot individual violin plots for features with values > 1\n",
    "    for column in features_gt_one.columns:\n",
    "        plt.figure(figsize=(8, 8), dpi=150)\n",
    "        sns.violinplot(y=features_gt_one[column], inner='quartile', palette='coolwarm')\n",
    "        plt.title(f'Distribution of Feature: {column} (Values > 1)')\n",
    "        plt.show()\n",
    "\n",
    "def normalize_features(features_df, feature_range=(0, 1)):\n",
    "    \"\"\"\n",
    "    Normalizes all numeric features in the DataFrame to a specified range using Min-Max scaling.\n",
    "\n",
    "    Parameters:\n",
    "        features_df (pd.DataFrame): A DataFrame containing feature columns.\n",
    "        feature_range (tuple): Desired range for the scaled data (default is (0, 1)).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with normalized features.\n",
    "    \"\"\"\n",
    "    # Select only numeric columns\n",
    "    numeric_features = features_df.select_dtypes(include=['number'])\n",
    "\n",
    "    # Initialize the MinMaxScaler with the desired range\n",
    "    scaler = MinMaxScaler(feature_range=feature_range)\n",
    "\n",
    "    # Fit and transform the numeric features\n",
    "    normalized_data = scaler.fit_transform(numeric_features)\n",
    "\n",
    "    # Create a DataFrame from the normalized data, retaining original feature names\n",
    "    normalized_df = pd.DataFrame(normalized_data, columns=numeric_features.columns, index=features_df.index)\n",
    "\n",
    "    # Return DataFrame with normalized features\n",
    "    return normalized_df\n",
    "\n",
    "def plot_feature_pairwise_scatter(features_df):\n",
    "    \"\"\"\n",
    "    Creates a large scatter plot matrix for each pair of features in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        features_df (pd.DataFrame): A DataFrame containing feature columns.\n",
    "    \"\"\"\n",
    "    # Select only numeric columns for plotting\n",
    "    numeric_features = features_df.select_dtypes(include=['number'])\n",
    "\n",
    "    # Set up the pairplot with a larger figure size\n",
    "    sns.pairplot(numeric_features, height=2, plot_kws={'s': 10})  # 's' controls marker size\n",
    "\n",
    "    # Show the plot\n",
    "    plt.suptitle(\"Pairwise Scatter Plot of Features\", y=1.02)  # Adjust title position\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>median</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ambiguity_mention</th>\n",
       "      <td>0.089438</td>\n",
       "      <td>0.204601</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.043</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t1</th>\n",
       "      <td>0.675959</td>\n",
       "      <td>0.404836</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t2</th>\n",
       "      <td>0.341781</td>\n",
       "      <td>0.400609</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t3</th>\n",
       "      <td>0.110151</td>\n",
       "      <td>0.252059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t4</th>\n",
       "      <td>0.031438</td>\n",
       "      <td>0.130991</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t5</th>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.063011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t1</th>\n",
       "      <td>0.914126</td>\n",
       "      <td>0.183264</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.909</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t2</th>\n",
       "      <td>0.191219</td>\n",
       "      <td>0.317063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.286</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t3</th>\n",
       "      <td>0.052608</td>\n",
       "      <td>0.168843</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t4</th>\n",
       "      <td>0.014509</td>\n",
       "      <td>0.079560</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t5</th>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.040908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc</th>\n",
       "      <td>0.122861</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descNgram</th>\n",
       "      <td>0.180925</td>\n",
       "      <td>0.177323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.288</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ed_score</th>\n",
       "      <td>0.918328</td>\n",
       "      <td>0.216692</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_score</th>\n",
       "      <td>0.992713</td>\n",
       "      <td>0.039472</td>\n",
       "      <td>0.334</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccardNgram_score</th>\n",
       "      <td>0.900998</td>\n",
       "      <td>0.246646</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_score</th>\n",
       "      <td>0.870418</td>\n",
       "      <td>0.284499</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_entity</th>\n",
       "      <td>24.645716</td>\n",
       "      <td>15.952489</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>245.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_mention</th>\n",
       "      <td>24.411462</td>\n",
       "      <td>15.764119</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>31.000</td>\n",
       "      <td>245.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncorrects_tokens</th>\n",
       "      <td>0.958736</td>\n",
       "      <td>0.154246</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ntoken_entity</th>\n",
       "      <td>3.436509</td>\n",
       "      <td>2.222873</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>41.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ntoken_mention</th>\n",
       "      <td>3.401033</td>\n",
       "      <td>2.196027</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>41.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_obj_ne</th>\n",
       "      <td>0.144615</td>\n",
       "      <td>0.206716</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_lit_all_datatype</th>\n",
       "      <td>0.015495</td>\n",
       "      <td>0.064873</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_lit_datatype</th>\n",
       "      <td>0.162202</td>\n",
       "      <td>0.333827</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_lit_row</th>\n",
       "      <td>0.080263</td>\n",
       "      <td>0.121885</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_ne</th>\n",
       "      <td>0.343473</td>\n",
       "      <td>0.278400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>0.017223</td>\n",
       "      <td>0.028737</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_score</th>\n",
       "      <td>0.197991</td>\n",
       "      <td>0.354082</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean    std_dev    min     25%  median     75%  \\\n",
       "ambiguity_mention         0.089438   0.204601  0.000   0.020   0.023   0.043   \n",
       "cpa_t1                    0.675959   0.404836  0.000   0.250   0.900   1.000   \n",
       "cpa_t2                    0.341781   0.400609  0.000   0.000   0.055   0.778   \n",
       "cpa_t3                    0.110151   0.252059  0.000   0.000   0.000   0.021   \n",
       "cpa_t4                    0.031438   0.130991  0.000   0.000   0.000   0.000   \n",
       "cpa_t5                    0.009168   0.063011  0.000   0.000   0.000   0.000   \n",
       "cta_t1                    0.914126   0.183264  0.000   0.909   1.000   1.000   \n",
       "cta_t2                    0.191219   0.317063  0.000   0.000   0.000   0.286   \n",
       "cta_t3                    0.052608   0.168843  0.000   0.000   0.000   0.000   \n",
       "cta_t4                    0.014509   0.079560  0.000   0.000   0.000   0.000   \n",
       "cta_t5                    0.004317   0.040908  0.000   0.000   0.000   0.000   \n",
       "desc                      0.122861   0.148662  0.000   0.000   0.091   0.200   \n",
       "descNgram                 0.180925   0.177323  0.000   0.000   0.149   0.288   \n",
       "ed_score                  0.918328   0.216692  0.000   1.000   1.000   1.000   \n",
       "es_score                  0.992713   0.039472  0.334   1.000   1.000   1.000   \n",
       "jaccardNgram_score        0.900998   0.246646  0.000   1.000   1.000   1.000   \n",
       "jaccard_score             0.870418   0.284499  0.000   1.000   1.000   1.000   \n",
       "length_entity            24.645716  15.952489  1.000  14.000  22.000  32.000   \n",
       "length_mention           24.411462  15.764119  1.000  14.000  21.000  31.000   \n",
       "ncorrects_tokens          0.958736   0.154246  0.000   1.000   1.000   1.000   \n",
       "ntoken_entity             3.436509   2.222873  1.000   2.000   3.000   4.000   \n",
       "ntoken_mention            3.401033   2.196027  1.000   2.000   3.000   4.000   \n",
       "p_obj_ne                  0.144615   0.206716  0.000   0.000   0.000   0.333   \n",
       "p_subj_lit_all_datatype   0.015495   0.064873  0.000   0.000   0.000   0.000   \n",
       "p_subj_lit_datatype       0.162202   0.333827  0.000   0.000   0.000   0.000   \n",
       "p_subj_lit_row            0.080263   0.121885  0.000   0.000   0.024   0.122   \n",
       "p_subj_ne                 0.343473   0.278400  0.000   0.000   0.410   0.600   \n",
       "popularity                0.017223   0.028737  0.000   0.000   0.010   0.020   \n",
       "pos_score                 0.197991   0.354082  0.020   0.020   0.020   0.080   \n",
       "\n",
       "                             max  \n",
       "ambiguity_mention          1.000  \n",
       "cpa_t1                     1.000  \n",
       "cpa_t2                     1.000  \n",
       "cpa_t3                     1.000  \n",
       "cpa_t4                     1.000  \n",
       "cpa_t5                     1.000  \n",
       "cta_t1                     1.000  \n",
       "cta_t2                     1.000  \n",
       "cta_t3                     1.000  \n",
       "cta_t4                     1.000  \n",
       "cta_t5                     1.000  \n",
       "desc                       1.000  \n",
       "descNgram                  1.000  \n",
       "ed_score                   1.000  \n",
       "es_score                   1.000  \n",
       "jaccardNgram_score         1.000  \n",
       "jaccard_score              1.000  \n",
       "length_entity            245.000  \n",
       "length_mention           245.000  \n",
       "ncorrects_tokens           1.000  \n",
       "ntoken_entity             41.000  \n",
       "ntoken_mention            41.000  \n",
       "p_obj_ne                   0.835  \n",
       "p_subj_lit_all_datatype    1.000  \n",
       "p_subj_lit_datatype        1.002  \n",
       "p_subj_lit_row             0.964  \n",
       "p_subj_ne                  0.858  \n",
       "popularity                 0.400  \n",
       "pos_score                  1.000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_distribution_statistics(semtab_business_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>median</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ambiguity_mention</th>\n",
       "      <td>0.128346</td>\n",
       "      <td>0.256206</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t1</th>\n",
       "      <td>0.021254</td>\n",
       "      <td>0.046103</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t2</th>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t3</th>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t4</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t5</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t1</th>\n",
       "      <td>0.133393</td>\n",
       "      <td>0.109787</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t2</th>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.076461</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t3</th>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.036532</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t4</th>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.020316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t5</th>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.013136</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc</th>\n",
       "      <td>0.052564</td>\n",
       "      <td>0.097563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descNgram</th>\n",
       "      <td>0.106423</td>\n",
       "      <td>0.161463</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ed_score</th>\n",
       "      <td>0.787915</td>\n",
       "      <td>0.273175</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_score</th>\n",
       "      <td>0.985499</td>\n",
       "      <td>0.046029</td>\n",
       "      <td>0.412</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccardNgram_score</th>\n",
       "      <td>0.786829</td>\n",
       "      <td>0.295538</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_score</th>\n",
       "      <td>0.779501</td>\n",
       "      <td>0.266219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_entity</th>\n",
       "      <td>16.895064</td>\n",
       "      <td>12.388215</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.00</td>\n",
       "      <td>15.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>242.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_mention</th>\n",
       "      <td>19.529837</td>\n",
       "      <td>13.864502</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.00</td>\n",
       "      <td>17.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>276.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncorrects_tokens</th>\n",
       "      <td>0.925515</td>\n",
       "      <td>0.168699</td>\n",
       "      <td>0.053</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ntoken_entity</th>\n",
       "      <td>2.349682</td>\n",
       "      <td>1.555922</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>43.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ntoken_mention</th>\n",
       "      <td>2.742671</td>\n",
       "      <td>1.811011</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>36.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_obj_ne</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_lit_all_datatype</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_lit_datatype</th>\n",
       "      <td>0.153960</td>\n",
       "      <td>0.276369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.171</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_lit_row</th>\n",
       "      <td>0.073157</td>\n",
       "      <td>0.103436</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_ne</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>0.023062</td>\n",
       "      <td>0.044573</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_score</th>\n",
       "      <td>0.086683</td>\n",
       "      <td>0.191037</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.043</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean    std_dev    min   25%  median     75%  \\\n",
       "ambiguity_mention         0.128346   0.256206  0.000  0.00   0.022   0.093   \n",
       "cpa_t1                    0.021254   0.046103  0.000  0.00   0.000   0.015   \n",
       "cpa_t2                    0.003394   0.013246  0.000  0.00   0.000   0.000   \n",
       "cpa_t3                    0.000374   0.002812  0.000  0.00   0.000   0.000   \n",
       "cpa_t4                    0.000014   0.000381  0.000  0.00   0.000   0.000   \n",
       "cpa_t5                    0.000003   0.000177  0.000  0.00   0.000   0.000   \n",
       "cta_t1                    0.133393   0.109787  0.000  0.04   0.120   0.200   \n",
       "cta_t2                    0.042836   0.076461  0.000  0.00   0.000   0.080   \n",
       "cta_t3                    0.017576   0.036532  0.000  0.00   0.000   0.040   \n",
       "cta_t4                    0.007010   0.020316  0.000  0.00   0.000   0.000   \n",
       "cta_t5                    0.003050   0.013136  0.000  0.00   0.000   0.000   \n",
       "desc                      0.052564   0.097563  0.000  0.00   0.000   0.111   \n",
       "descNgram                 0.106423   0.161463  0.000  0.00   0.000   0.205   \n",
       "ed_score                  0.787915   0.273175  0.010  0.57   1.000   1.000   \n",
       "es_score                  0.985499   0.046029  0.412  1.00   1.000   1.000   \n",
       "jaccardNgram_score        0.786829   0.295538  0.000  0.58   1.000   1.000   \n",
       "jaccard_score             0.779501   0.266219  0.000  0.50   1.000   1.000   \n",
       "length_entity            16.895064  12.388215  1.000  7.00  15.000  24.000   \n",
       "length_mention           19.529837  13.864502  1.000  9.00  17.000  26.000   \n",
       "ncorrects_tokens          0.925515   0.168699  0.053  1.00   1.000   1.000   \n",
       "ntoken_entity             2.349682   1.555922  1.000  1.00   2.000   3.000   \n",
       "ntoken_mention            2.742671   1.811011  1.000  1.00   2.000   3.000   \n",
       "p_obj_ne                  0.000000   0.000000  0.000  0.00   0.000   0.000   \n",
       "p_subj_lit_all_datatype   0.000000   0.000000  0.000  0.00   0.000   0.000   \n",
       "p_subj_lit_datatype       0.153960   0.276369  0.000  0.00   0.000   0.171   \n",
       "p_subj_lit_row            0.073157   0.103436  0.000  0.00   0.031   0.100   \n",
       "p_subj_ne                 0.000000   0.000000  0.000  0.00   0.000   0.000   \n",
       "popularity                0.023062   0.044573  0.000  0.00   0.000   0.030   \n",
       "pos_score                 0.086683   0.191037  0.020  0.02   0.020   0.043   \n",
       "\n",
       "                             max  \n",
       "ambiguity_mention          1.000  \n",
       "cpa_t1                     0.487  \n",
       "cpa_t2                     0.348  \n",
       "cpa_t3                     0.122  \n",
       "cpa_t4                     0.036  \n",
       "cpa_t5                     0.033  \n",
       "cta_t1                     1.000  \n",
       "cta_t2                     1.000  \n",
       "cta_t3                     0.320  \n",
       "cta_t4                     0.280  \n",
       "cta_t5                     0.240  \n",
       "desc                       0.778  \n",
       "descNgram                  0.800  \n",
       "ed_score                   1.000  \n",
       "es_score                   1.000  \n",
       "jaccardNgram_score         1.000  \n",
       "jaccard_score              1.000  \n",
       "length_entity            242.000  \n",
       "length_mention           276.000  \n",
       "ncorrects_tokens           1.000  \n",
       "ntoken_entity             43.000  \n",
       "ntoken_mention            36.000  \n",
       "p_obj_ne                   0.000  \n",
       "p_subj_lit_all_datatype    0.000  \n",
       "p_subj_lit_datatype        1.000  \n",
       "p_subj_lit_row             0.667  \n",
       "p_subj_ne                  0.000  \n",
       "popularity                 0.470  \n",
       "pos_score                  1.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_distribution_statistics(github_dataset_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ambiguity_mention</th>\n",
       "      <td>1.371559e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t1</th>\n",
       "      <td>2.159104e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t2</th>\n",
       "      <td>1.830046e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t3</th>\n",
       "      <td>1.557449e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t4</th>\n",
       "      <td>1.412909e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa_t5</th>\n",
       "      <td>1.336183e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t1</th>\n",
       "      <td>2.492165e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t2</th>\n",
       "      <td>1.332075e+10</td>\n",
       "      <td>1.283536e-191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t3</th>\n",
       "      <td>1.150747e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t4</th>\n",
       "      <td>1.171178e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cta_t5</th>\n",
       "      <td>1.210381e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desc</th>\n",
       "      <td>1.624067e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descNgram</th>\n",
       "      <td>1.638822e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ed_score</th>\n",
       "      <td>1.582176e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es_score</th>\n",
       "      <td>1.382227e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccardNgram_score</th>\n",
       "      <td>1.553468e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_score</th>\n",
       "      <td>1.541167e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_entity</th>\n",
       "      <td>1.695540e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_mention</th>\n",
       "      <td>1.541764e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncorrects_tokens</th>\n",
       "      <td>1.387057e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ntoken_entity</th>\n",
       "      <td>1.698660e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ntoken_mention</th>\n",
       "      <td>1.528861e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_obj_ne</th>\n",
       "      <td>1.735497e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_lit_all_datatype</th>\n",
       "      <td>1.486746e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_lit_datatype</th>\n",
       "      <td>1.113956e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_lit_row</th>\n",
       "      <td>1.207524e+10</td>\n",
       "      <td>1.190551e-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_subj_ne</th>\n",
       "      <td>2.089827e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>1.277926e+10</td>\n",
       "      <td>4.851339e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_score</th>\n",
       "      <td>1.273685e+10</td>\n",
       "      <td>1.167211e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            statistic        p_value\n",
       "ambiguity_mention        1.371559e+10   0.000000e+00\n",
       "cpa_t1                   2.159104e+10   0.000000e+00\n",
       "cpa_t2                   1.830046e+10   0.000000e+00\n",
       "cpa_t3                   1.557449e+10   0.000000e+00\n",
       "cpa_t4                   1.412909e+10   0.000000e+00\n",
       "cpa_t5                   1.336183e+10   0.000000e+00\n",
       "cta_t1                   2.492165e+10   0.000000e+00\n",
       "cta_t2                   1.332075e+10  1.283536e-191\n",
       "cta_t3                   1.150747e+10   0.000000e+00\n",
       "cta_t4                   1.171178e+10   0.000000e+00\n",
       "cta_t5                   1.210381e+10   0.000000e+00\n",
       "desc                     1.624067e+10   0.000000e+00\n",
       "descNgram                1.638822e+10   0.000000e+00\n",
       "ed_score                 1.582176e+10   0.000000e+00\n",
       "es_score                 1.382227e+10   0.000000e+00\n",
       "jaccardNgram_score       1.553468e+10   0.000000e+00\n",
       "jaccard_score            1.541167e+10   0.000000e+00\n",
       "length_entity            1.695540e+10   0.000000e+00\n",
       "length_mention           1.541764e+10   0.000000e+00\n",
       "ncorrects_tokens         1.387057e+10   0.000000e+00\n",
       "ntoken_entity            1.698660e+10   0.000000e+00\n",
       "ntoken_mention           1.528861e+10   0.000000e+00\n",
       "p_obj_ne                 1.735497e+10   0.000000e+00\n",
       "p_subj_lit_all_datatype  1.486746e+10   0.000000e+00\n",
       "p_subj_lit_datatype      1.113956e+10   0.000000e+00\n",
       "p_subj_lit_row           1.207524e+10  1.190551e-111\n",
       "p_subj_ne                2.089827e+10   0.000000e+00\n",
       "popularity               1.277926e+10   4.851339e-09\n",
       "pos_score                1.273685e+10   1.167211e-05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to store test results for each feature\n",
    "results = {}\n",
    "\n",
    "for feature in semtab_business_features_df.columns:\n",
    "    # Extract the feature data from each dataset\n",
    "    data1 = semtab_business_features_df[feature]\n",
    "    data2 = github_dataset_features_df[feature]\n",
    "    \n",
    "    # Perform the Mann-Whitney U Test\n",
    "    stat, p_value = mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "    \n",
    "    # Store the result\n",
    "    results[feature] = {'statistic': stat, 'p_value': p_value}\n",
    "\n",
    "# Convert results to a DataFrame for easier interpretation\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
